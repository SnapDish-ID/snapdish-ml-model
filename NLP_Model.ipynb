{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XI7m_Ylyh0Vk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    a = tf.constant(a, dtype=tf.float32)\n",
        "    b = tf.constant(b, dtype=tf.float32)\n",
        "    dot_product = tf.reduce_sum(a * b, axis=1)\n",
        "    norm_a = tf.sqrt(tf.reduce_sum(a**2, axis=1))\n",
        "    norm_b = tf.sqrt(tf.reduce_sum(b**2, axis=1))\n",
        "    similarity = dot_product / (norm_a * norm_b)\n",
        "    return similarity\n",
        "\n",
        "main_ingredient = \"tempe\"\n",
        "ingredients_list = [\"paprika\", \"tempe\", \"kentang\", \"jahe\", \"bawang putih\"]\n",
        "\n",
        "csv_file = \"dataset.csv\"\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "ingredients = \", \".join(ingredients_list)\n",
        "\n",
        "category = df[df['Category'] == main_ingredient]\n",
        "dataset_ingredients = category[\"Ingredients Cleaned\"].astype(str).tolist()\n",
        "\n",
        "max_vocab_size = 10000\n",
        "sequence_length = 50\n",
        "\n",
        "vectorizer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=max_vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "vectorizer.adapt(dataset_ingredients)\n",
        "encoded_dataset = vectorizer(dataset_ingredients).numpy()\n",
        "encoded_input = vectorizer([ingredients]).numpy()\n",
        "\n",
        "similarity_scores = cosine_similarity(encoded_dataset, encoded_input).numpy()\n",
        "category['similarities'] = similarity_scores\n",
        "\n",
        "results = category.sort_values('similarities',ascending=False).drop_duplicates(subset=['Title Cleaned'], keep='first').iloc[:3]\n",
        "\n",
        "results"
      ]
    }
  ]
}
